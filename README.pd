# Titanic Survival Prediction - Machine Learning Project

## Project Overview
This project predicts passenger survival on the Titanic using **Logistic Regression** and **Random Forest** models.  
The goal was to build a **working baseline model**, understand key features affecting survival, and evaluate model performance.

---

## Dataset
- Source: [Kaggle Titanic Dataset](https://www.kaggle.com/c/titanic/data)  
- Features used:
  - **Sex**: Male/Female  
  - **Age**: Passenger age  
  - **Fare**: Ticket fare  
  - **Pclass**: Passenger class (1, 2, 3)  
  - **Cabin/Deck**: Deck letter extracted from Cabin  
  - **Embarked**: Port of embarkation  
- Features dropped:
  - **Name, Ticket** → too unique and not predictive

---

## Preprocessing
- Filled missing values (Age, Embarked, Cabin → Deck)  
- Encoded categorical features:
  - `Sex` → 0/1  
  - `Deck` and `Embarked` → one-hot encoding  
- Scaled numeric features for Logistic Regression

---

## Models Trained
1. **Logistic Regression**
   - Features scaled  
   - Accuracy: **79.33%**
2. **Random Forest**
   - Original features (no scaling)  
   - Accuracy: **78.21%**

> Logistic Regression performed slightly better and was chosen as the final model.

---

## Key Observations
- **Sex**: Females mostly survived → highly predictive  
- **Deck**: Upper deck passengers had higher survival → extracted from Cabin  
- **Fare & Pclass**: Higher class/fare slightly increased survival chances  
- Random Forest did not outperform Logistic Regression  
- Logistic Regression converged properly after feature scaling  
- Model predicts **non-survivors better than survivors**

---

## Evaluation
- Accuracy: 79.33%  
- Confusion matrix:

|               | Pred 0 (Not Survived) | Pred 1 (Survived) |
|---------------|----------------------|------------------|
| Actual 0      | 95                   | 15               |
| Actual 1      | 22                   | 47               |

- Most errors occur for survivors misclassified as non-survivors  

- Precision, Recall, F1-Score (from classification report):

| Class | Precision | Recall | F1-Score |
|-------|-----------|--------|----------|
| 0     | 0.81      | 0.86   | 0.84     |
| 1     | 0.76      | 0.68   | 0.72     |

---

## Usage
1. Load `train.xlsx` and `test.xlsx`  
2. Run preprocessing script  
3. Train Logistic Regression or Random Forest  
4. Predict survival and evaluate

---

## GitHub Commits
- Initial commit: project files and cleaned dataset  
- Small commit: model training and evaluation scripts  
- Future updates: additional features or models

---

## Conclusion
- Logistic Regression is a **simple, interpretable, and effective baseline model**  
- Feature engineering (Sex, Deck, Embarked) significantly improved performance  
- Confusion matrix and metrics provide insight into model strengths and weaknesses  
- Model is ready for basic survival prediction and further experimentation
